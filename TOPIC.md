изначальная проблема:
хочется быстро парсить историю цены предметов в стиме
стандартное огранчиение составляет 6 запроссов в минуту с 1 ип адреса
в стиме для кс го больше 25 тысяч предметов

даже если оставить только 5000 предметов, то со скоростью 6 предметов в минуту это будет занимать
14 часов, что очень долго. и данные успеют уже протухнуть

изначальные идеи:
парсить бесплатные прокси с сайтов и использовать их


использовать тор
для С# нашел библиотечку https://github.com/joelverhagen/TorSharp
которая позволяет запускать несколько торов и управлять ими

основые полезные настройки это настрйока частоты смены выходного ip адреса
и принудительная смена адреса
так же можно настраивать выходные страны и прочее
минусы:
плохо работает или совсем не работает удаление процессов и бинарей после завершения работы
на каждый тор копируются все бинари из-за чего буквально через несколько запусков рабочая дирректория раздувается до 20+ гигабайт

так же каждый из запускаемых на винде торов кушает процессор и память
из-за чего после 40 инстансов процессор начинает долбиться в 100%
а каждый тор кушает примерно 80МБ памяти

так же нет гарантий что все 40 запущенных торов будут иметь разные выходные ноды если явно за этим не следить и не управлять.
а для убравления есть только метод смены личности, что вообще говоря не гарантирует уникальность, когда мы смотрим на группу из нескольких торов

после всех неудач я решил посмотреть в сторону бесплатных прокси.
казалось, что это простой и надежный способ т.к сайты предоставляют сотни и даже тысячи прокси.

чтобы првоерить пркоси на работоспосбность достаточно всего лишь отправить запрос на любой сайт и при этом указать прокси для выполнения этого запроса.
если ответ пришел, пркоси работает, если нет, значит есть проблемы

но все оказалось не так радужно.
во первых из всех собранных прокси только около 0.1% проходят проверку на работоспособность
во вторых из прокси прошла проверку, то не факт что через секунду она сможет пройти еще одну
в третьих оказалось, что на c# сложно, а может быть даже невозможно написать быстрый многопоточный прокси чекер, связано это с тем, что прокси для соединения настраиваются при создании HttpClient
т.е для каждого прокси нужно создавать новый клиент, но вот незадача, создавать httpClient дорого даже сами майки рекомендуют создавать его синглтоном в приложениях.
так же даже после dispose httpclient оставляет после себя открыте соединения в статусе ожидания,
чтоб потом их переиспользовать. но вот в чем проблема
каждое такое соединение предназнаечно для конкретного адреса
т.е если оно установлено к ресурсу А, то не выйдет его использовать для подклчюения к ресурсу Б
https://www.aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/

поэтому я отказался от идеи писать чекер на шарпе

быстренько в гугле нашелся проект парсера и чекера прокис на питоне https://github.com/monosans/proxy-scraper-checker

не долго думая написал небольшую обертку на шарпе для запуска процесса питона и выгребания ответа из json файла со всей нужной информацией. Но вот в чем незадача, это довольно долго. примерно 13-15 минут на полный парсинг и проверку прокси и это при условии, что я использоал все доступные соединения винды

я решил перепсиать его так, чтоб он сам переодически запускал парсинг прокси добавлял их в список, проверял и выдавал их по rest api

после нескольких вечеров вайбкодинга с оптимизациями и огребанием от питона я допилил этот кодец, теперь я мог получать из шарпового кода список уже проверенных прокси и использовать их для парсинга.
Но н евсе так просто. оказалось, что прмиерно 95% всех живых прокси проверят проверку на работоспособность всего лишь 1 раз. После этого они надоло умирают

тут будет график с распределением успешности проверок

после такого неожиданного прикола я понял, что с бесплатными прокси ничего дельного сделать не получится.
Они быстро умирают, имеют огромные задержки от 10+ сек и кто му же нужно много времени и ресурсов, чтоб их добыть.

Пообщавшись с коллегой на работе он мне предложил использовать xray впн? и другие технологии обхода блокировок, я сделал небольшое исследование, на гитхае есть репозитории, где публикуют бесплатные строки подключения, но в целом это ничем не отличается от ситуации с бесплатными прокси.
Строк подклчюения много, но большая часть из них не работает. Так же нужен дополнительный софт для работы, что будет кушать ресурсы и его нужно еще как-то настраивать


поэтому я пошел в гугл, оказалось, что существуют платные сервисы, предоставляющие прокси пулы, если кому интересно, искать нужн опримерно такое "rotating proxy pool"
Почему-то сразу я не смог выйти на эту фразу, но после того, как я её увидел, напсиал ради интереса
"tor rotating proxy" и о чудо, оказывается яне один такой извращенный гений, решивший использовать тор в таких целях

Был найден вот такой гитхаб репозиторий с докер образом 
https://github.com/zhaow-de/rotating-tor-http-proxy

внутри там используется запуск нескольких торов
privoxy для того чтоб сконвертить хттп трафик в socks5
и haproxy для rounrobin палансировки трафика между инстансами тора

звучит неплохо и я решил это потестить.

И по первым тестам это действительно хорошо работает. но автор почему-то установил огранчиение в 40 тор инстансов, мне это не понравилось я склонил репошку, испарвил файл и запустил 100.
но работать стало только хуже)

странно, посмотрев файлы с конфигурацией и увидев, что автор предлагает каждому инстансу свою страну, звучит круто, ведь я могу каждому инстансу указать свою страну и тогда они гарантирвоано не будут пересекаться по ип адресам, что позволит мне вообще забыть о проблеме того, что нужно поддерживать н уникальных адресов на инстансах